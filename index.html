<!DOCTYPE html>
<html lang="en">

<head>
	<title>Meike Zehlike</title>

	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="author" content="Meike Zehlike">
	<meta name="description"
		content="I am a Ph.D. student at Humboldt Universit√§t zu Berlin and the Max Planck Institute for Software Systems (MPI-SWS) in the Social Computing Research group. I am advised by Ulf Leser, Carlos Castillo and Krishna Gummadi. I was a visiting researcher at WSSC with Carlos Castillo, UPF Barcelona, Spain in 2018 and at VIDA lab with Julia Stoyanovich, New York University, USA in 2019. I completed my Diploma degree in Computer Science at the Technische Universit√§t Dresden with Nico Hoffmann and Uwe Petersohn as my advisors, where I developed a machine learning algorithm to recognize vascular pathologies in thermographic images of the brain. I studied Computer Science at MIIT (–ú–ò–ò–¢) in Moscow, Russia in 2009/2010, and at INSA in Lyon, France 2010. My research interests center around artificial intelligence and its social impact, algorithmic discrimination, fairness and algorithmic exploitation.">
	<meta property="og:image" content="https://MilkaLichtblau.github.io/assets/images/profile.jpg">
	<meta property="og:image:type" content="image/jpeg">
	<meta property="og:image:width" content="661">
	<meta property="og:image:height" content="662">
	<meta name="keywords"
		content="scientist, science, wissenschaftler, wissenschaftlerin, phd, student, artificial intelligence, k√ºnstliche intelligenz, ethics, ethik, germany, deutschland, berlin, informatik, computer science, doktorand, fairness, algorithmic fairness">

	<!-- Google Font -->
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">

	<!-- FontAwesome JS-->
	<script defer src="https://use.fontawesome.com/releases/v5.1.1/js/all.js"
		integrity="sha384-BtvRZcyfv4r0x/phJt9Y9HhnN5ur1Z+kZbKVgzVBAlQZX4jvAuImlIz+bG7TS00a"
		crossorigin="anonymous"></script>
	<script data-ad-client="ca-pub-9807457463500719" async
		src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
		integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
		crossorigin="anonymous"></script>
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
		integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
		crossorigin="anonymous"></script>

	<!-- Theme CSS -->
	<link id="theme-style" rel="stylesheet" href="assets/css/pillar-1.css">


</head>

<body>

	<script>
		var names = {
			"meike_zehlike": ["Meike Zehlike", "https://milkalichtblau.github.io/"],
			"krishna_gummadi": ["Krishna P. Gummadi", "http://www.mpi-sws.org/~gummadi/"],
			"abhijnan_chakraborty": ["Abhijnan Chakraborty", "http://cse.iitkgp.ac.in/~abhijnan/"],
			"carlos_castillo": ["Carlos Castillo", "https://chato.cl/"],
			"francesco_bonchi": ["Francesco Bonchi", "http://www.francescobonchi.com/"],
			"ricardo_baeza": ["Ricardo Baeza-Yates", "http://www.baeza.cl/"],
			"sara_hajian": ["Sara Hajian", "https://www.linkedin.com/in/sara-hajian/"],
			"tom_suehr": ["Tom S√ºhr", "https://www.linkedin.com/in/tom-s%C3%BChr-436999147/"],
			"asia_biega": ["Asia J. Biega", "https://www.microsoft.com/en-us/research/people/jobiega/"],
			"ivan_kitanovski": ["Ivan Kitanovski", "https://finki.ukim.mk/en/staff/ivan-kitanovski"],
			"emil_wiedemann": ["Emil Wiedemann", "https://www.uni-ulm.de/mawi/iaa/members/wiedemann/"],
			"mohamed_megahed": ["Mohamed Megahed", "https://github.com/megantosh"],
			"philipp_hacker": ["Philipp Hacker", "https://hu-berlin.academia.edu/PhilippHacker"]
		};
		function parse_author_to_html(author) {
			return '<a href="' + author[1] + '" target="_blank">' + author[0] + '</a>';
		}

		function get_authors(authors) {
			var str = "";
			if (authors.length == 1) {
				str = parse_author_to_html(names[authors[0]]) + ".";
			}
			else if (authors.length == 2) {
				str = parse_author_to_html(names[authors[0]]) + " and " + parse_author_to_html(names[authors[1]]) + ".";
			}
			else {
				for (var i = 0; i < authors.length - 1; i++) {
					str += parse_author_to_html(names[authors[i]]) + ", ";
				}
				str += "and " + parse_author_to_html(names[authors[i]]) + ".";
			}
			return str
		}

	</script>
	<article class="resume-wrapper text-center position-relative">
		<div class="resume-wrapper-inner mx-auto text-left bg-white shadow-lg">
			<header class="resume-header pt-4 pt-md-0">
				<div class="media flex-column flex-md-row">
					<img class="mr-3 img-fluid picture mx-auto" src="assets/images/profile.jpg" alt="">
					<div class="media-body p-4 d-flex flex-column flex-md-row mx-auto mx-lg-0">
						<div class="primary-info">
							<h1 class="name mt-0 mb-1 text-white text-uppercase text-uppercase">Meike Zehlike</h1>
							<div class="title mb-3">Ph.D. Student at HU Berlin and MPI-SWS</div>
							<ul class="list-unstyled">
								<li class="mb-2"><a href="#"><i class="far fa-envelope fa-fw mr-2"
											data-fa-transform="grow-3"></i>meikezehlike [AT] mpi-sws [DOT] org</a></li>
								<li class="mb-2"><a href="pdf/zehlike_cv.pdf"><i
											class="far fa-file-pdf fa-fw mr-2" data-fa-transform="grow-3"></i>CV</a>
								</li>
							</ul>
						</div>
						<!--//primary-info-->
						<div class="secondary-info ml-md-auto mt-2">
							<ul class="resume-social list-unstyled">
								<li class="mb-3"><a
										href="https://scholar.google.com/citations?user=2zK_5AwAAAAJ&hl=en"><span
											class="fa-container text-center mr-2"><i
												class="fab fa-google fa-fw"></i></span>Google Schoolar</a>
								</li>
								<li class="mb-3"><a href="https://www.linkedin.com/in/meike-zehlike/"><span
											class="fa-container text-center mr-2"><i
												class="fab fa-linkedin-in fa-fw"></i></span>linkedin.com/in/meike-zehlike</a>
								</li>
								<li class="mb-3"><a href="https://github.com/MilkaLichtblau/"><span
											class="fa-container text-center mr-2"><i
												class="fab fa-github-alt fa-fw"></i></span>github.com/MilkaLichtblau</a>
								</li>
								<li class="mb-3"><a href="https://twitter.com/MilkaLichtblau"><span
											class="fa-container text-center mr-2"><i
												class="fab fa-twitter fa-fw"></i></span>@MilkaLichtblau</a></li>
							</ul>
						</div>
						<!--//secondary-info-->

					</div>
					<!--//media-body-->
				</div>
				<!--//media-->
			</header>
			<div class="resume-body p-5">
				<section class="resume-section summary-section mb-5">
					<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">About me</h2>
					<div class="resume-section-content">
						<p class="mb-0">I am a Ph.D. student at Humboldt Universit√§t zu Berlin and the Max Planck Institute for Software Systems (<a href="https://www.mpi-sws.org/">MPI-SWS</a>) in the <a href="http://socialnetworks.mpi-sws.org">Social Computing Research</a> group. I am advised by Ulf Leser, Carlos Castillo and Krishna Gummadi. I was a visiting researcher at WSSC with Carlos Castillo, UPF Barcelona, Spain in 2018 and at VIDA lab with Julia Stoyanovich, New York University, USA in 2019. I completed my Diploma degree in Computer Science at the Technische Universit√§t Dresden with Nico Hoffmann and Uwe Petersohn as my advisors, where I developed a machine learning algorithm to recognize vascular pathologies in thermographic images of the brain. I studied Computer Science at MIIT (–ú–ò–ò–¢) in Moscow, Russia in 2009/2010, and at INSA in Lyon, France 2010. 
						<br>
						<br>
						My research interests center around artificial intelligence and its social impact, algorithmic discrimination, fairness and algorithmic exploitation.

					</div>
				</section>
				<!--//summary-section-->
				<div class="row">
					<div class="col-lg-9">
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Selected Publications
							</h2>
							<h6>For full list of publications, kindly check my <a href="https://scholar.google.com/citations?user=2zK_5AwAAAAJ">Google Scholar</a> or
								<a href="https://dblp.uni-trier.de/pers/z/Zehlike:Meike">DBLP</a> Profile.
							</h6>
							<br>

							<div class="resume-section-content">
								<div class="resume position-relative">
									<article class="resume position-relative mb-5">
										<div class="resume-timeline-item-header mb-2">
											<div class="d-flex flex-column flex-md-row">
												<h4 class="resume-timeline-item-header font-weight-bold mb-1">Journals
												</h4>
											</div>
											<!--//row-->
										</div>
										<!--//resume-timeline-item-header-->
										<ul class="list-inline">
											<li>
											<h6 class="resume-timeline-item-desc-heading font-weight-bold">Matching code and law: achieving algorithmic fairness with optimal transport.</h6>
											<li>
												<script>document.write(get_authors(["meike_zehlike", "philipp_hacker", "emil_wiedemann"]))</script>
											</li>
											<li>Data Mining and Knowledge Discovery. Springer. Volume 34, Issue 1,
												January 2020.</li>

											<ul class="list-inline">
												<li class="list-inline-item resume-degree-org"><a
														href="#dmkd_journal" data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item resume-degree-org"><a
														href="pdf/1712.07924.pdf" target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item resume-degree-org"><a
														href="bibtex/zehlike2020matching.bib" target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
												<li class="list-inline-item resume-degree-org"><a
														href="https://github.com/MilkaLichtblau/ContinuousFairness"
														target="_blank">
														<span class="badge badge-primary badge-pill">GitHub</span>
													</a></li>
											</ul>
											</li>
											<div id="dmkd_journal" class="collapse">
												<p class="font-italic"><b>Abstract:</b> Increasingly, discrimination by algorithms is perceived as a societal and legal problem. As a response, a number of criteria for implementing algorithmic fairness in machine learning have been developed in the literature. This paper proposes the continuous fairness algorithm (CFAùúÉ) which enables a continuous interpolation between different fairness definitions. More specifically, we make three main contributions to the existing literature. First, our approach allows the decision maker to continuously vary between specific concepts of individual and group fairness. As a consequence, the algorithm enables the decision maker to adopt intermediate ‚Äúworldviews‚Äù on the degree of discrimination encoded in algorithmic processes, adding nuance to the extreme cases of ‚Äúwe‚Äôre all equal‚Äù and ‚Äúwhat you see is what you get‚Äù proposed so far in the literature. Second, we use optimal transport theory, and specifically the concept of the barycenter, to maximize decision maker utility under the chosen fairness constraints. Third, the algorithm is able to handle cases of intersectionality, i.e., of multi-dimensional discrimination of certain groups on grounds of several criteria. We discuss three main examples (credit applications; college admissions; insurance contracts) and map out the legal and policy implications of our approach. The explicit formalization of the trade-off between individual and group fairness allows this post-processing approach to be tailored to different situational contexts in which one or the other fairness criterion may take precedence. Finally, we evaluate our model experimentally.</p>
											</div>
										</ul>
									</article>
									<article class="resume position-relative mb-5">

										<div class="resume-timeline-item-header mb-2">
											<div class="d-flex flex-column flex-md-row">
												<h4 class="resume-timeline-item-header font-weight-bold mb-1">
													Conference Proceedings
												</h4>
											</div>
											<!--//row-->
										</div>
										<!--//resume-timeline-item-header-->
										<ul class="list-inline">
											<li>
												<h6 class="resume-timeline-item-desc-heading font-weight-bold">
													Towards a Flexible Framework for Algorithmic Fairness</h6>
											<li>
												<script>document.write(get_authors(["philipp_hacker", "emil_wiedemann", "meike_zehlike"]))</script>
											</li>
											<li>Proceedings of INFORMATIK 2020. Karlsruhe, Germany. October, 2020.</li>

											<ul class="list-inline">
												<li class="list-inline-item"><a href="#informatik2020"
														data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item"><a href="pdf/2010.07848.pdf"
														target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item"><a
														href="bibtex/hacker2020towards.bib" target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
											</ul>
											</li>
											<div id="informatik2020" class="collapse">
												<p class="font-italic"><b>Abstract:</b> Increasingly, scholars seek to integrate legal and technological insights to combat bias in AI systems. In recent years, many different definitions for ensuring non-discrimination in algorithmic decision systems have been put forward. In this paper, we first briefly describe the EU law framework covering cases of algorithmic discrimination. Second, we present an algorithm that harnesses optimal transport to provide a flexible framework to interpolate between different fairness definitions. Third, we show that important normative and legal challenges remain for the implementation of algorithmic fairness interventions in real-world scenarios. Overall, the paper seeks to contribute to the quest for flexible technical frameworks that can be adapted to varying legal and normative fairness constraints.
												</p>
											</div>
										</ul>
										<ul class="list-inline">
											<li>
												<h6 class="resume-timeline-item-desc-heading font-weight-bold">
													Reducing disparate exposure in ranking: A learning to rank approach</h6>
											<li>
												<script>document.write(get_authors(["meike_zehlike", "carlos_castillo"]))</script>
											</li>
											<li>Proceedings of The Web Conference 2020 (WWW'20). Taipeh, Taiwan. April, 2020.</li>

											<ul class="list-inline">
												<li class="list-inline-item"><a href="#www-deltr"
														data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item"><a href="pdf/3366424.3380048.pdf"
														target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item"><a
														href="bibtex/zehlike2020deltr.bib" target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
												<li class="list-inline-item"><a
														href="https://github.com/MilkaLichtblau/DELTR-Experiments" target="_blank">
														<span class="badge badge-primary badge-pill">GitHub</span>
													</a></li>

											</ul>
											</li>
											<div id="www-deltr" class="collapse">
												<p class="font-italic"><b>Abstract:</b> Ranked search results have become the main mechanism by which we ÓÄõnd content, products, places, and people online. Thus their ordering contributes not only to the satisfaction of the searcher, but also to career and business opportunities, educational placement, and even social success of those being ranked. Researchers have become increasingly concerned with systematic biases in data-driven ranking models, and various post-processing methods have been proposed to mitigate discrimination and inequality of opportunity. This approach, however, has the disadvantage that it still allows an unfair ranking model to be trained. In this paper we explore a new in-processing approach: DELTR, a learning-to-rank framework that addresses potential issues of discrimination and unequal opportunity in rankings at training time. We measure these problems in terms of discrepancies in the average group exposure and design a ranker that optimizes search results in terms of relevance and in terms of reducing such discrepancies. We perform an extensive experimental study showing that being ‚Äúcolorblind‚Äù can be among the best or the worst choices from the perspective of relevance and exposure, depending on how much and which kind of bias is present in the training set. We show that our in-processing method performs better in terms of relevance and exposure than a pre-processing and a post-processing method across all tested scenarios.
												</p>
											</div>
										</ul>
										<ul class="list-inline">
											<li>
												<h6 class="resume-timeline-item-desc-heading font-weight-bold">
													FairSearch: A Tool For Fairness in Ranked Search Results</h6>
											<li>
												<script>document.write(get_authors(["meike_zehlike", "tom_suehr", "carlos_castillo", "ivan_kitanovski"]))</script>
											</li>
											<li>Companion Proceedings of the Web Conference 2020 (WWW'20), Taipeh, Taiwan.
												April 2020.</li>

											<ul class="list-inline">
												<li class="list-inline-item"><a href="#www-fairsearch"
														data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item"><a href="pdf/3366424.3383534.pdf"
														target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item"><a href="bibtex/zehlike2020fairsearch.bib"
														target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
												<li class="list-inline-item"><a
														href="https://github.com/fair-search" target="_blank">
														<span class="badge badge-primary badge-pill">GitHub</span>
													</a></li>

											</ul>
											</li>
											<div id="www-fairsearch" class="collapse">
												<p class="font-italic"><b>Abstract:</b> Ranked search results and recommendations have become the mainmechanism by which we find content, products, places, and people online. With hiring, selecting, purchasing, and dating being increasingly mediated by algorithms, rankings may determine business opportunities, education, access to benefits, and even social success. It is therefore of societal and ethical importance to ask whether search results can demote, marginalize, or exclude individuals of unprivileged groups or promote products with undesired features. In this paper we present FairSearch, the first fair open source search API to provide fairness notions in ranked search results. We implement two well-known algorithms from the literature, namely FA*IR (Zehlike et al., 2017) and DELTR (Zehlike and Castillo, 2018)and provide them as stand-alone libraries in Python and Java. Additionally we implement interfaces to Elasticsearch for both algorithms, a well-known search engine API based on Apache Lucene. The interfaces use the aforementioned Java libraries and enable search engine developers who wish to ensure fair search results of different styles to easily integrate DELTR and FA*IR into their existing Elasticsearch environment.
												</p>
											</div>
										</ul>

										<ul class="list-inline">
											<li>
												<h6 class="resume-timeline-item-desc-heading font-weight-bold">
													Two-sided fairness for repeated matchings in two-sided markets: A case study of a ride-hailing platform</h6>
											<li>
												<script>document.write(get_authors(["tom_suehr", "asia_biega", "meike_zehlike", "krishna_gummadi", "abhijnan_chakraborty"]))</script>
											</li>
											<li>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining
												(KDD'19). Anchorage, Alaska, USA. August, 2019.</li>

											<ul class="list-inline">
												<li class="list-inline-item"><a href="#kdd-matchings"
														data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item"><a
														href="pdf/3292500.3330793.pdf" target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item"><a
														href="suhr2019matching.bib"
														target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
											</ul>
											</li>
											<div id="kdd-matchings" class="collapse">
												<p class="font-italic"><b>Abstract:</b> Ride hailing platforms, such as Uber, Lyft, Ola or DiDi, have traditionally focused on the satisfaction of the passengers, or on boosting successful business transactions. However, recent studies provide a multitude of reasons to worry about the drivers in the ride hailing ecosystem. The concerns range from bad working conditions and worker manipulation to discrimination against minorities. With the sharing economy ecosystem growing, more and more drivers financially depend on online platforms and their algorithms to secure a living. It is pertinent to ask what a fair distribution of income on such platforms is and what power and means the platform has in shaping these distributions. In this paper, we analyze job assignments of a major taxi company and observe that there is significant inequality in the driver income distribution. We propose a novel framework to think about fairness in the matching mechanisms of ride hailing platforms. Specifically, our notion of fairness relies on the idea that, spread over time, all drivers should receive benefits proportional to the amount of time they are active in the platform. We postulate that by not requiring every match to be fair, but rather distributing fairness over time, we can achieve better overall benefit for the drivers and the passengers. We experiment with various optimization problems and heuristics to explore the means of achieving two-sided fairness, and investigate their caveats and side-effects. Overall, our work takes the first step towards rethinking fairness in ride hailing platforms with an additional emphasis on the well-being of drivers.
												</p>
											</div>
										</ul>
										<ul class="list-inline">
											<li>
												<h6 class="resume-timeline-item-desc-heading font-weight-bold">
													Fa*ir: A fair top-k ranking algorithm</h6>
											<li>
												<script>document.write(get_authors(["meike_zehlike", "francesco_bonchi", "carlos_castillo", "sara_hajian", "mohamed_megahed", "ricardo_baeza"]))</script>
											</li>
											<li>Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM'17). Singapore.
												November, 2017.</li>

											<ul class="list-inline">
												<li class="list-inline-item"><a href="#cikm-fair"
														data-toggle="collapse">
														<span class="badge badge-dark badge-pill">Abstract</span></a>
												</li>
												<li class="list-inline-item"><a href="pdf/3132847.3132938.pdf"
														target="_blank">
														<span class="badge badge-danger badge-pill">PDF</span></a>
												</li>
												<li class="list-inline-item"><a href="bibtex/zehlike2017fair.bib"
														target="_blank">
														<span class="badge badge-secondary badge-pill">BibTeX</span></a>
												</li>
												<li class="list-inline-item"><a
														href="https://github.com/MilkaLichtblau/FA-IR_Ranking" target="_blank">
														<span class="badge badge-primary badge-pill">GitHub</span>
													</a></li>

											</ul>
											</li>
											<div id="cikm-fair" class="collapse">
												<p class="font-italic"><b>Abstract:</b> In this work, we define and solve the Fair Top-k Ranking problem, in which we want to determine a subset of k candidates from a large pool of n ¬ª k candidates, maximizing utility (i.e., select the "best" candidates) subject to group fairness criteria.

Our ranked group fairness definition extends group fairness using the standard notion of protected groups and is based on ensuring that the proportion of protected candidates in every prefix of the top-k ranking remains statistically above or indistinguishable from a given minimum. Utility is operationalized in two ways: (i) every candidate included in the top-k should be more qualified than every candidate not included; and (ii) for every pair of candidates in the top-k, the more qualified candidate should be ranked above.

An efficient algorithm is presented for producing the Fair Top-k Ranking, and tested experimentally on existing datasets as well as new datasets released with this paper, showing that our approach yields small distortions with respect to rankings that maximize utility without considering fairness criteria. To the best of our knowledge, this is the first algorithm grounded in statistical tests that can mitigate biases in the representation of an under-represented group along a ranked list.
												</p>
											</div>
										</ul>

										
									</article>
									<!--//resume-timeline-item-->

								</div>
								<!--//resume-timeline-->

						</section>
						<!--//publication-section-->
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Systems and
								Applications
							</h2>
							<ul>
								<li>
									<strong>Discrimination In Employee Development:</strong>
									A consultancy project on potential algorithmic discrimination in employee promotion together with Germany's largest labor union, the IG Metall.
								</li>
								<li>
									<a href="https://github.com/fair-search" target="_blank">
										<strong>FairSearch:</strong>
									</a> A set of tools for ranking post-processing (FA*IR) and in-processing (DELTR) with fairness constraints.
								</li>
								<li>
									<a href="https://fairnessmeasures.github.io/" target="_blank">
										<strong>Fairness Measures:</strong>
									</a> Datasets and software for detecting algorithmic discrimination.
								</li>
							</ul>

						</section>
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Awards and Scholarships
							</h2>
							<ul>
								<li> (2019) <a
										href="https://buildyourfuture.withgoogle.com/scholarships/#link-scholarship"><strong>Generation Google Scholarship EMEA</strong></a>: a 7,000 EUR award for the impact on diversity, demonstrated leadership and strong academic background.</li>
								<li>(since 2018) <a href="https://ellis.eu/phd-postdoc/"><strong>ELLIS PhD Fellow</strong></a>: Research Network of the European Laboratory for Learning and Intelligent Systems.</li>
								<li>(2017) <a href="https://www.datatransparencylab.org/"><strong>Data Transparency Lab Research</a> Grant</strong>: Grant of 50,000 EUR for the design and implementation of web tools that enable fairness accountability and transparency in machine learning systems.</li>

								<li>(2016) <a href="https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/soamed-en"><strong>SOAMED Graduate School</strong></a>: PhD school on service-oriented Architectures for the Integration of Software-based Processes, exemplified by Health Care Systems and Medical Technology</li>
								<li>(2010) <a href="https://www.femtec.org/"><strong>Femtec Network</a> Career Building Scholarship</strong>: Career building program for female future leaders from science, technology, engineering and mathematics</li>

								<li>(2010) <strong>Erasmus Scholarship</strong>: Semester abroad in Lyon, France</li>
								<li>(2009) <strong>DAAD "GoEast" Scholarship</strong>: Semester abroad in Moscow, Russia</li>
								<li>(2009) <strong>DAAD Summer School Tomsk/Moscow Scholarship</strong>: Language summer school in Tomsk and Moscow, Russia</li>
							</ul>
						</section>


						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Invited Talks
							</h2>
							<ul>
								<li>(2020) <strong>Matching Code and Law</strong>. Bias@MD4SG, virtual venue.</li>
								<li>(2020) <strong>Bias in AI</strong>. Track Keynote at INFORMATIK 2020, Karlsruhe, DE.</li>
								<li>(2020) <strong>Fairness in Algorithmic Decision Making</strong>. FTA Live 2020, Berlin, DE.</li>
								<li>(2020) <strong>Panel: Wie wird k√ºnstliche Intelligenz geschlechtergerecht</strong>. <a
										href="https://www.igmetall-bbs.de/aktuelles/meldung/diskussion-wie-wird-kuenstliche-intelligenz-geschlechtergerecht/">Podiumsdiskussion</a>. Berlin, DE.
								</li>

								<li>(2019) <strong>Matching Code and Law</strong>. Columbia University, New York City, NY, US.</li>

								<li>(2019) <strong>Matching Code and Law</strong>. IBM Research, Yorktown, NY, US.</li>
								<li>(2019) <strong>Disparate Exposure in Learning to Rank</strong>. Microsoft Research, New York City, NY, US.</li>
								<li>(2019) <strong>Fairness-Aware Ranking Algorithms</strong>. CapGemini, DE.</li>
								<li>(2019) <strong>Fairness in Algorithmic Decision Making</strong>. Yale University, New Haven, CT, US.</li>
								<li>(2019) <strong>Fairness-Aware Ranking Algorithms</strong>. Technische Universit√§t Berlin. Berlin, DE.</li>
								<li>(2019) <strong>Panel: Brauchen wir mehr Diversit√§t im Datenjournalismus</strong>. nr19 Jahreskonferenz. Hamburg, DE</li>
								<li>(2019) <strong>Fairness-Aware Ranking Algorithms</strong>. Freie Universit√§t Berlin. Berlin, DE.</li>
								<li>(2018) <strong>Fairness-Aware Ranking Algorithms</strong>. RWTH Aachen. Aachen, DE.</li>
								<li>(2017) <strong>Frameworks of Bias in Computer Systems and their Application in Rankings</strong>. Workshop on Data and Algorithmic Bias. DAB'17. Singapore.</li>
								<li>(2017) <strong>Panel: Algorithmic Fairness and Bias in Data</strong>. Workshop on Data and Algorithmic Bias. DAB'17. Singapore.</li>
								<li>(2017) <strong>On Fairness in Ranked Search Algorithms</strong>. Universit√§t Hamburg. Hamburg, DE</li>
							</ul>

						</section>
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Press Coverage
							</h2>

							<p>Here is some coverage of newspaper articles written by me on the topic of algorithmic fairness and TV appearances. </p>

							<h6>Newspaper Articles</h6>
							<ul>
								<li><strong>Unfair:</strong> S√ºddeutsche Zeitung Nr. 104, 6th May 2019, p.9</li>
								<li><strong>Algorithmen gegen Diskriminierung: </strong> <a href="https://gegenblende.dgb.de/artikel/++co++2b8f6854-7c67-11e9-
9f8e-52540088cada">Gegenblende - Debattenmagazin, 22nd May 2019</a></li>
							</ul>
							<h6>TV Appearances</h6>
							<ul>

								<li><strong>Algorithms rule us all:</strong>
									<a href="https://www.vpro.nl/programmas/tegenlicht/kijk/afleveringen/2017-2018/verslaafd-aan-het-algoritme"
										target="_blank">VPRO Documentary, </a>
									<a href="https://youtu.be/NFF_wj5jmiQ"> YouTube</a>
								</li>
							</ul>


						</section>
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Professional Service
							</h2>
							<ul>
								<li>Reviewer, Elsevier IP&M, Special Issue in Fairness in IR</li>
								<li>PC Member, FAccT 2021</li>
								<li>Track Chair 'Ethics in AI', Informatik 2020</li>
								<li>PC Member, SIGIR 2020</li>
								<li>PC Member, BIAS 2020</li>
								<li>PC Member, FACTS-IR 2019</li>
								<li>Reviewer, EDBT 2019</li>
								<li>Reviewer FAT* 2019</li>
								<li>Academic Senate Member, Faculty Board Member. 2017 - 2019. TU Berlin</li>
								<li>Appointment Committee Member. 2017 - 2018. TU Berlin</li>
							</ul>


						</section>
						<section class="resume-section experience-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Teaching and Supervision
							</h2>
							<h6>Lecturer</h6>
							<ul>
								<li>(2018 - 2019) Practical Project for Master Students, TU Berlin</li>
								<li>(2017 - 2018) Practical Course for Bachelor Students, TU Berlin</li>
							</ul>
							<h6>Master Theses Supervision</h6>
							<ul>
								<li>Michal Jirku: Algorithmic Fairness Development in a Competitive Setting</li>
								<li>Frederic Mauss: Creating a gender-specific data set about the users of StackOverflow</li>
								<li>Stefanie Quach: Extending the DELTR Algorithm to Multinomial Use Cases</li>
							</ul>
							<h6>Bachelor Theses Supervision</h6>
							<ul>
								<li>Flora Muscinelli: Mapping Algorithmic Fairness is Contextual</li>
								<li>Tom S√ºhr: Two-Sided Fairness for Repeated Matchings in Two-Sided Markets</li>
								<li>Jan Steffen Pre√üler: A Data Collection to Develop Fair Machine Learning Algorithms</li>
								<li>Gina-Theresa Diehn: FA*IR as Pre-Processing Fair Machine Learning Approach</li>
								<li>Simon Huber: Generating Discriminatory Datasets by Usage of Wasserstein Generative Adversarial Networks</li>
								<li>Laura Mons: Benchmarking for Fair Machine Learning Algorithms</li>
								<li>Hyerim Hwang: Extension of the FA*IR Top-k Ranking Algorithm to Multinomial Use Cases</li>
							</ul>

						<!--//experience-section-->
					</div>
					<div class="col-lg-3">
						<section class="resume-section interests-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Interests</h2>
							<div class="resume-section-content">
								<ul class="list-unstyled">
									<li class="mb-1">Algorithmic Fairness</li>
									<li class="mb-1">Discrimination and Exploitation</li>
									<li class="mb-1">Political Philosophy</li>
									<li class="mb-1">Machine Learning</li>
								</ul>
							</div>
						</section>
						<section class="resume-section education-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Education</h2>
							<div class="resume-section-content">
								<ul class="list-unstyled">
									<li class="mb-2">
										<div class="resume-degree font-weight-bold">Ph.D. in Computer Science</div>
										<div class="resume-degree-org"><a href="https://mpi-sws.org">Max Planck
												Institute for Software Systems (MPI-SWS)</a></div>
										<div class="resume-degree-org"><a
												href="https://www.hu-berlin.de/en">Humboldt Universit√§t zu Berlin</a></div>
										<div class="resume-degree-time">2016 - present</div>
									</li>
									<li class="mb-2">
										<div class="resume-degree font-weight-bold">Diploma in Computer Science</div>
										<div class="resume-degree-org"><a href="https://tu-dresden.de/?set_language=en">Technische Universit√§t Dresden</a></div>
										<div class="resume-degree-time">2006 - 2014</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">Student Exchange</div>
										<div class="resume-degree-org"><a href="https://www.insa-lyon.fr/en/">INSA, Lyon</a></div>
										<div class="resume-degree-time">2010</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">Student Exchange</div>
										<div class="resume-degree-org"><a href="http://en.russia.edu.ru/vuz/2150/">MIIT, Moscow</a></div>
										<div class="resume-degree-time">2009 - 2010</div>
									</li>
								</ul>
							</div>
						</section>
						<section class="resume-section language-section mb-5">
							<h2 class="resume-section-title text-uppercase font-weight-bold pb-3 mb-3">Languages</h2>
							<div class="resume-section-content">
								<ul class="list-unstyled resume-lang-list">
									<li class="mb-2"><span class="resume-lang-name font-weight-bold">German</span>
										<small class="text-muted font-weight-normal">(Native)</small></li>
									<li class="mb-2"><span class="resume-lang-name font-weight-bold">English</span> <small
											class="text-muted font-weight-normal">(Professional)</small></li>
									<li class="mb-2"><span class="resume-lang-name font-weight-bold">French</span> <small
											class="text-muted font-weight-normal">(Advanced)</small></li>
									<li class="mb-2"><span class="resume-lang-name font-weight-bold">Russian</span> <small
											class="text-muted font-weight-normal">(Advanced)</small></li>
								</ul>
							</div>
						</section>
						<!--//language-section-->
					</div>
				</div>
				<!--//row-->
			</div>
			<!--//resume-body-->


		</div>
	</article>


	<footer class="footer text-center pt-2 pb-5">
		<!--/* This template is released under the Creative Commons Attribution 3.0 License. Please keep the attribution link below when using for your own project. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
		<small>¬© Copyright by Max Planck Institute for Software Systems 2020. All rights reserved. <a
				href="https://imprint.mpi-klsb.mpg.de/sws/people/johnme">Imprint</a> / <a
				href="https://data-protection.mpi-klsb.mpg.de/sws/people/johnme">Data Protection</a></small>
		</br>
		<small class="copyright">Design adapted from the HTML5 template by <a href="http://themes.3rdwavemedia.com"
				target="_blank">Xiaoying Riley</a></small>
	</footer>

</body>


<!--<!--Global site tag(gtag.js) - Google Analytics-->-->
<!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-162290164-1"></script>-->
<!--<script>-->
<!--	window.dataLayer = window.dataLayer || [];-->
<!--	function gtag() { dataLayer.push(arguments); }-->
<!--	gtag('js', new Date());-->

<!--	gtag('config', 'UA-162290164-1');-->
<!--</script>-->


</html>
